{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:red\">Intro to Neural Decoding</span>\n",
    "\n",
    "Neural decoding is the study of what information is available in the electrical activity of individual cells or networks of neurons by trying to identify what stimulus or event elicits a particular pattern of neural activity.\n",
    "\n",
    "It can be used predict what people were dreaming about, imagining, looking at or listening too, among many other exciting areas of interest.\n",
    "\n",
    "In this tutorial, we will go through a few different ways to decode your neural data. This lab will also introduce you to the data that we will be using for our last problem set.\n",
    "\n",
    "### Part 1: Classifying by computing distance to centroid\n",
    "\n",
    "Here, we will generate two slightly separated clusters of random data. This will serve as our training set. We will then generate test points drawn from both of our distributions. We will compute the distance of each test point to the center of both clusters and use the smallest distance as our prediction. We will then test the accuracy of our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing helful packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-da3b8c085f7f>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-da3b8c085f7f>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    plt.scatter(, c='blue')\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Set random number seed to make results replicable\n",
    "np.random.seed(10)\n",
    "\n",
    "# Define parameters of two data clusters\n",
    "m1 = np.array([0.05, 0.05])\n",
    "m2 = np.array([0.95, 0.95])\n",
    "sigma = np.eye(2)\n",
    "\n",
    "# Generate 100 data points from each cluster as training data\n",
    "data1 = np.random.multivariate_normal(m1,sigma,100)\n",
    "data2 = np.random.multivariate_normal(m2,sigma,100)\n",
    "\n",
    "# Plot the data: make a scatterplot with data1 as blue circles and data2 as red circles\n",
    "plt.figure()\n",
    "plt.scatter(, c='blue')\n",
    "plt.scatter(, c='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a loop of 100 steps, generate a test point either from m1 50% of the time and from m2 50% of the time. Using the imported **_pdist()_** function, compute the distance of your point to both means, and assign the point to the nearest mean. Record an accuracy of 1 for each trial if the correct mean is guessed, and record a 0 if it is not. What is your mean accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78\n"
     ]
    }
   ],
   "source": [
    "# Importing pdist function\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "# Initiate data structure for accuracy\n",
    "accuracy = np.zeros()\n",
    "mat1 = np.zeros()\n",
    "mat2 = np.zeros()\n",
    "\n",
    "# Loop to classify which group the test point is in\n",
    "for i in range():\n",
    "    # Conditional to randomly pick a point from m1 or m2\n",
    "\n",
    "    # Define test point \n",
    "    myPoint = np.random.multivariate_normal(myMean,sigma,1)\n",
    "    # calculate the distance to m1 and m2\n",
    "    mat1[0,:] = \n",
    "    mat1[1,:] = \n",
    "    mat2[0,:] = \n",
    "    mat2[1,:] = \n",
    "    \n",
    "    dist1 = pdist()\n",
    "    dist2 = pdist()\n",
    "    # Conditional to assign predicted class to be the class w/ smallest distance\n",
    "\n",
    "    # Conditional to determine error\n",
    "\n",
    "# Calculate accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: k-nearest neighbors\n",
    "\n",
    "If you correctly implemented the previous stategy, you should have obtained an accuracy around the 70-80%. This is above the level of random guessing (called \"chance-level performance\" - 50%), but it's not especially great either.\n",
    "\n",
    "Perhaps we can do better if we make our prediction based on look at the number of training points that are close to our test point. The number of test points we examine is known as k. Each gets one vote, and our predicted class is the majority class of these votes. For example, if k=5 and 3/5 are in category 1 while 2/5 are in category 2, we will predict that our test points is in category 1. Values of k are typically odd numbers to prevent tying.\n",
    "\n",
    "Let's implement a 5-nearest neighbor classifier on our data.\n",
    "\n",
    "Run the following cell to set up the necessary data structures for the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6fc94b866677>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# putting both sets together will make things easier later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mallData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mallData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mallData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# number of neighbors\n",
    "k = 5\n",
    "\n",
    "# putting both sets together will make things easier later\n",
    "allData = np.zeros((200,2))\n",
    "allData[:100,:] = data1\n",
    "allData[100:,:] = data2\n",
    "\n",
    "# category labels\n",
    "Class = np.zeros((200,1))\n",
    "Class[:100] = np.matlib.repmat(1,100,1)\n",
    "Class[100:] = np.matlib.repmat(2,100,1)\n",
    "\n",
    "# Splitting up the data into training and testing sets\n",
    "trainInds = np.zeros((160))\n",
    "trainInds[:80] = np.arange(0,80,1)\n",
    "trainInds[80:] = np.arange(100,180,1)\n",
    "trainInds = trainInds.astype(int)\n",
    "\n",
    "testInds = np.zeros((40))\n",
    "testInds[:20] = np.arange(80,100,1)\n",
    "testInds[20:] = np.arange(180,200,1)\n",
    "testInds = testInds.astype(int)\n",
    "\n",
    "trainData = allData[trainInds,:]\n",
    "testData = allData[testInds,:]\n",
    "\n",
    "trainClass = Class[trainInds,:]\n",
    "testClass = Class[testInds,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an outer loop, sample each of your saved testing points. Within an inner loop, compute the distance of your test point with each of the points in the training data. Save each of these distances. Outside of this inner loop, sort the distances in ascending order, and find the class of the k-smallest distances (ie. nearest neighbors). Choose the most frequent class to be the predicted class for the point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-117fd4947dbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# sample the ith test point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "accuracy = np.zeros(40)\n",
    "\n",
    "for i in range():\n",
    "    # sample the ith test point\n",
    "    \n",
    "    # Intialize storage space for points and distances\n",
    "    tempMat = np.zeros()\n",
    "    dist = np.zeros()\n",
    "    # compute distances to each point in training data in an inner loop\n",
    "    for j in range():\n",
    "        # Store points in tempMat\n",
    "        \n",
    "        # Store calculated distances in dist\n",
    "        dist[j] = pdist()\n",
    "        \n",
    "    # sorting distances\n",
    "    sortedDist = np.sort(dist)\n",
    "    sortedInds = np.searchsorted(dist,sortedDist)\n",
    "    winners = sortedInds[1:k]\n",
    "    \n",
    "    # Find out how many points are in each class\n",
    "    \n",
    "    \n",
    "    # Conditional to check if predicted class matches actual class\n",
    "\n",
    "# Calculate accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Correlation classifier\n",
    "\n",
    "For multivariate classifications, a simple but still powerful classification algorithm is the correlation classifier. Here, each feature of the input is correlated to the mean of each class observed in training, and the class that is most correlated with the rest item is taken to be the classifier's prediction.\n",
    "\n",
    "For this exercise, we will use one single neuron from the Zhang et al (2011) *PNAS*. Next week, you will be using the whole population of over 100 neurons that were recorded!\n",
    "\n",
    "The data are stored in the classificationData.mat file. In this structure, neuronData corresponds to the spikes count rate of a single neuron in the object-sensitive inferior temporary cortex in 150 ms bins over course of each of 420 trials. In this experiement, a monkey was viewing one of 7 objects, and the indices for each of these objects is in neuronInds. Finally, neuronLabels gives gives the object names in order. In other words, the second position of neuronLabels gives the object that corresponds to all of the 2's in neuronInds.\n",
    "\n",
    "Fill in the code below to create your correlation classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing package to load data\n",
    "from mat2array import loadmat\n",
    "\n",
    "# Loading and defining data\n",
    "classificationData = loadmat('classificationData.mat')\n",
    "neuronData = classificationData['neuronData']\n",
    "neuronInds = classificationData['neuronInds']\n",
    "neuronLabels = classificationData['neuronLabels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-2f75c209c6a1>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-2f75c209c6a1>\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    jData = copyData[]\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Initializing data storage for calculating accuracy\n",
    "accuracy = np.zeros()\n",
    "\n",
    "for i in range():\n",
    "    # define the ith point as the test point and corresponding class\n",
    "    \n",
    "    # creating training data out of the remaining 419 points\n",
    "    copyData = np.delete(neuronData, i, 0)\n",
    "    copyInds = np.delete(neuronInds, i, 0)  \n",
    "    # create a \"template\" that shows the average activation pattern for each object\n",
    "    testCorr = np.zeros()\n",
    "    # Initialize counter to index by image class.\n",
    "    ID = 1\n",
    "    for j in range(len(neuronLabels)):\n",
    "        # find all of the training trials for the jth object\n",
    "        jGroup, = np.where()\n",
    "        jData = copyData[]\n",
    "        jData = np.mean()\n",
    "        # Find correlation coefficient between training data and test point\n",
    "        testCorr[j] = np.corrcoef()[0,1]\n",
    "        \n",
    "        ID = ID + 1\n",
    "    # Choose the category with the highest correlation as the predicted class\n",
    "    predClass, = np.where()\n",
    "    # Conditional to check if this is correct and updates accuracy accordingly\n",
    "\n",
    "# Calculate accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have correctly implemented this procedure, you will get an accuracy of around 18%. How does this correspond to the level that you would expect through random guessing? How might you test whether statistically significantly higher than random guessing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
